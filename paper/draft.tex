% TODO: tempted to term this "Module-aware dynamic fragmentation, analysis, and reassembly" as Dialysis or refracture
% CFP: https://www.usenix.org/conference/atc20/call-for-papers
\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix2019_v3}

\usepackage{soul}
\usepackage{xspace}
\usepackage{color}

\def\omit#1{}
\def\eg{{\em e.g.}, }
\def\ie{{\em i.e.}, }
\def\etc{{\em etc.}\xspace}
\def\vs{{\em vs.}\xspace}
% \newcommand{\heading}[1]{\vspace{4pt}\noindent\textbf{#1}\enspace}
% No vspace, coz Usenix class already has paragraph space
\newcommand{\heading}[1]{\vspace{2pt}\noindent\textbf{#1}\enspace}
\newcommand{\ttt}[1]{\texttt{#1}}
\newcommand{\ttiny}[1]{\texttt{\scriptsize #1}}
\newcommand{\tcn}[1]{}

\newcommand{\cf}[1]{(\emph{Cf}.\S\ref{#1})}
\newcommand{\sx}[1]{(\S\ref{#1})}
\newcommand{\sys}{{\scshape Lya}\xspace}
\newcommand{\toy}{{\tt lya.js}\xspace}

\newcommand{\fra}{fragmentation\xspace} % fracture
\newcommand{\ana}{analysis\xspace}      % 
\newcommand{\ass}{reassembly\xspace}    % 
\newcommand{\Fra}{Fragmentation\xspace} % fracture
\newcommand{\Ana}{Analysis\xspace}      % 
\newcommand{\Ass}{Reassembly\xspace}    % 
\newcommand{\dia}{\fra, \ana, and \ass}

\newcommand{\nv}[1]{[{\color{cyan}#1 --- Nikos}]}
\newcommand{\review}[1]{{\color{red}#1}}
\newcommand{\TODO}[1]{\hl{\textbf{TODO:} #1}\xspace}
\newcommand{\todo}[1]{\hl{#1}\xspace}
\newcommand{\fixme}[1]{{\color{red}#1}}
\newcommand{\tc}{(\todo{cite})\xspace}
%-------------------------------------------------------------------------------
\begin{document}
%-------------------------------------------------------------------------------

%don't want date printed
\date{}

% make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf Library Dialysis with Lya}

%for single author (just remove % characters)
\author{
{\rm Anonymous Author(s)}\\
\normalsize{Submission \#225, 12 pages}\\
\normalsize{Additional Anonymized Material: \href{https://git.io/JvfCf}{https://git.io/JvfCf}.}
% {\rm Grigoris Ntousakis}\\
% Technical University of Crete
% \and
% {\rm Nikos Vasilakis}\\
% Massachusetts Institute of Technology
}

\maketitle

\begin{abstract}

This paper introduces \emph{library dialysis}, a novel dynamic-analysis technique specifically tailored to applications with many third-party libraries.
Such library over-reliance is a recent trend in software engineering:
  applications today rely recursively on hundreds of libraries, to the point where code written by their nominal developers is becoming only a small fraction of their total line count.
% On the surface, such reliance is beneficial, as it lowers development costs, aids targeted software testing, and enables code reuse;
Despite its benefits, such over-reliance creates many challenges for developers, exactly because their little knowledge of and visibility in the internals of these libraries:
  for example, security auditing and performance profiling---already challenging in monolithic applications---become extremely difficult in the presence of deeply-nested third-party code.

To address these challenges, library dialysis is a general technique that allows extracting meaningful insights with only a few lines of analysis-specific code.
This feature is achieved by automating dynamic \fra, \ana, and \ass of applications at the level of individual modules and during program execution, by wrapping and transforming the underlying dependency graph.
Operating at this level of granularity has several benefits:
  (i) it allows bolting library dialysis itself as a library onto existing runtime environments that do not feature dynamic analysis,
  (ii) it supports analysis expressions directly in the same language, tools, and abstractions as the host application language---eschewing low-level instrumentation, and %developers can use their tools 
  (iii) it features low performance overheads, to the point that has the potential to be used online.
% FIXME: It depends on the analysis
% Due to the in the host language and at a coarser granularity than full-fledged dynamic analysis, module dialysis 
% Operating at the granularity of library has several benefits: (i) ease (ii) performance (iii) while still getting 
%In a sense, modules are the right level of abstraction 

Our dialysis prototype, \sys, targets the JavaScript ecosystem, which counts over 1M libraries and is used on the web, server, and mobile.
We use a series of case-studies to motivate \sys's design, and demonstrate how \sys allows the analysis of both individual modules as well as multi-module application programs---all with a surprisingly   low developer effort and performance overhead:
  insightful analyses can be expressed in 10--20 lines of code, add a virtually imperceptible increase in the load latency of individual modules, and scale to real applications with hundreds of modules.

% Module dialysis can be bolted on existing language runtime environments in a language-agnostic fashion 
% % By leveraging the ubiquity of third-party modules in today's applications
% Such modules can be part of third-party packages or of the language's standard library;
%   the latter is important for resources that are part of the broader environment where the application is executing, such as the operating system and the network.

\end{abstract}

\section{Introduction}
\label{intro}

Dynamic analysis is a type of program analysis performed by (and while) executing a program with the goal of identifying information about the program.
Such information may include the ability to infer execution invariants, check security constraints, and extract performance characteristics (multiple citations).

% Where dynamic analysis shines is
Dynamic analysis occupies a clear spot in the space of analysis has clear strengths and weaknesses.
  (i) involve current runtime information, such as the workload patterns
  (ii) have full visibility into the current execution (no path explosion),
  (iii) is the only viable option in dynamic programming languages---such as Ruby, Python, 
Examples of information not analyzable statically include runtime code evaluation, runtime introspection and reflection, as well as multi-lingual support.
Dynamic analysis is a particularly good fit for the analysis of dynamic languages.

Unfortunately, however, reaping these benefits comes with significant overheads in terms of developer effort and runtime performance.
One approach is to instrument the program requires an in-depth understanding of its internals and associated tools (\eg instruction set \etc).
Another approach is to modify the runtime environment of the program---\eg JavaScript's V8 engine.
Problem-specific solutions require significant investment outside the language's mental model and  

This paper proposes a novel approach to dynamic analysis, termed \emph{module-aware dynamic analysis} and implemented in \sys.
(i) at a somewhat coarser granularity, but still offering insights---and in a semantics-aware way tailored to the programming language.
(ii) bolt on
Our approach is applicable to any language that supports some notion of modularity, runtime introspection, and .
It plugs into the module-loading capability of the runtime system to insert key hooks for inserting 
After the parsing and interpretation phases of module loading complete, 
 which are then parsed and interpreted and 
Surprisingly, as we show in this paper, this architecture requires \emph{no} modifications to the language runtime---that is, it is backward-compatible with vanilla unmodified language runtime environments.

Its key strategy is to fracture applications at the boundaries of modules, instrument their interfaces (including direct accesses) using meta-programming capabilities, and recombine them 
By combining visiiblity into both built-in and third-party modules, \sys can get gather important information for 
at a much lower cost---both in terms of runtime performance and developer effort.

% to enable module-aware dynamic analysis are general
To achieve this, module-aware dynamic analysis leverages several techniques.
It plugs into the module manager;
wraps interfaces
(i) bolt on, meaning
(ii) high-performance, and 
(iii) low effort 

As shown later, these capabilities are generally available in all dynamic programming languages---\eg 

To demonstrate the effectiveness of our techniques, we
  (i) build a prototype of module-aware dynamic analysis for server-side JavaScript, called \sys; and
  (ii) develop a diverse set of analyses---including an allow/deny security analysis, a profiling analysis showing hot modules, a synthesis-oriented analysis on input-output data, and an analysis enforcing a static union-based type system at runtime.
  (iii)  and use \sys to evaluate these analyses on three levels:
    synthetic micro-benchmarks, that highlight certain features;
    single-module meso-benchmarks, that allow comparison with other dynamic analysis tools; and
    end-to-end full-application macro-benchmarks, that shows \sys's behavior of the system on realistic workloads. 
\sys's implementation and evaluation drives the design requirements for \sys and highlights the benefits of bolt-on module-aware dynamic analysis.

Our contributions, presented in \S\ref{bg}--\ref{impl} include:
\begin{itemize}
\item We characterize the shared needs of four case-study analyses~\sx{bg} for which an implementation from scratch would require a significant investment in terms of developer effort.
\item We present the design of the bolt-on module-oriented dynamic analysis~\sx{design}, which meets the requirements of the four case-study analyses.
\item We describe designs of four 
\item We discuss our prototype implementation, \sys, as a pluggable library for the JavaScript ecosystem~\sx{impl}; our evaluation shows that \sys incurs minimal performance overheads over the respective baseline runtime.
\end{itemize}

Aside from the sections corresponding to these contributions (\S\ref{bg}--\ref{impl}), the paper discusses \sys's limitations and its application to other environments~\sx{diss};
   it compares \sys with related prior work in the literature~\sx{rw}; and draws appropriate conclusions~\sx{end}.


\section{Background, Examples, and Goals}
\label{bg}

A single application today often incorporates multiple libraries\footnote{We use the terms ``library'', ``package'', and ``module'' interchangeably.} written and published by several different authors.
The emerging development process should (and to a certain extent, does) simplify the development and testing process;
  unfortunately, good abstractions are sealed (\ie they do not leak between abstraction layers), which makes the inspection of a library difficult.

\subsection{Modularity Today}

languages provide module systems

closely coupled with the runtime

A module uses a \ttt{import} function and returns an export .
Intuitively a map

Several details:
  same module at multiple levels, and the module cache
  sometime it's the same, some times it;s not
  module resolution algorithm

\subsection{Motivating Examples}

Having reviewed the building blocks and underlying techniques that power modularity, we now turn to examples of dynamic analysis that today are difficult or require specialized solutions:
  (i) an allow/deny security analysis,
  (ii) a profiling analysis showing hot modules,
  (iii) a synthesis-oriented analysis on input-output data, and
  (iv) an analysis enforcing a static union-based type system at runtime.
These examples illuminate key design requirements for \sys's implementation of module-level dynamic analysis.

\heading{Security Analysis}
Today's ubiquitous reliance on third-party modules has led to an explosion of supply-chain attacks~\cite{maass2016theory, lauinger2017thou, long2015owasp, cadariu2015tracking, breakapp:plos:2017, snyk}.
Both bugs and malicious code in imported modules provide attack vectors that are exploitable long after modules reach their end-users.
As development-time module boundaries do not exist at runtime, modules end up executing with no meaningful isolation or privilege separation guarantees between each other and the trusted portions of an application.
The popularity of certain libraries---depended upon by tens of thousands of other libraries or applications---allows vulnerabilities deep in the dependency graph to affect a great number of applications~\cite{kuppusamy2016diplomat, leftpad, npmstudy:19}.
Discovered vulnerabilities are becoming harder to eradicate, as updates are fetched automatically~\cite{npmFailure} and module unpublishing is becoming a multi-step process to avoid breaking applications~\cite{npmUnpublish}.
Worst of all,\omit{package developers accidentally publishing their security} leaked publishing tokens allow anyone to update packages with code that will eventually reach end-users via package updates~\cite{eslint1, eslint2}.

Recent work~\cite{dld:08, sandcrust, tsampas2017towards, breakapp:ndss:2018} has shown that 
The key issue underlying the \ttt{event-stream} attack is that any third-party fragment of an application has unrestricted access to the functionality available to the rest of application. % and is exploitable.
Some of this functionality is \emph{explicitly} provided by other libraries such as \ttt{fs} and \ttt{http}.
Other functionality is \emph{implicitly} provided by the programming language;
  examples include the ability to use global variables, import modules, and access the cache of the loaded modules.
Both explicitly and implicitly provided functionality is exploitable by third-party code.
While it may be needed for the application to function as a whole, it is not necessarily needed by \ttt{event-stream}.
% However, not \emph{all} of this capability is needed by \emph{all} of the modules during \emph{all} of the time.
MLC shows great promise, as it can
(i) retrofit security into \emph{legacy} systems not designed with security as their primary concern,
(ii) protect against a plethora of \emph{real} attacks stemming from defective, subverted, and malicious elements, and
(iii) shield against attacker-controlled components with \emph{unknown} vulnerabilities and powerful \emph{runtime} code evaluation. % (\eg \texttt{eval}).

To make this concrete, we are introducing

\heading{Performance Diagnosis}
Developers use various techniques to understand such problems.
For example, collected traces can be replayed against off-line versions of the system and statistical profiling can identify hot code-paths.
These techniques, however, require some degree of \emph{manual} effort:
  capturing traces, setting up testbeds, replaying traces, analyzing statistics, and debugging performance are all tedious and time-consuming tasks.
Pervasiveness of third-party modules and heavy code reuse in modern applications compound the challenge, as the causes may lie deep in the dependency chain.

Once provided with a few recipes, \sys starts monitoring the performance of the corresponding modules in order to detect bottlenecked modules.
A key observation is the semantic isomorphism between calling a function and passing a message~\cite{scheme:98, duality:79}.
This allows viewing a series of calls as a stream of messages. % that 
% at each module boundary 
Module boundaries can be viewed as (virtual) queues of messages that await processing.
% and applying windowed average operations on a 
Overwhelming a module causes its ingress queue to grow.
% MM: related to the sync vs. async
% As the queue grows due to module overloading, new messages will be processed only after all other messages have been processed.
At some point, the waiting time of newly-arrived messages becomes longer than the time to send the messages to a remote copy of the module, run the call there, and return the results back to their intended recipient.
% Intuitively, it makes sense to schedule a queue on a remote processor when the wait time at the end of the queue becomes longer than scheduling the message to a remote queue.

To make this concrete, we are introducing

\heading{Type and Invariant Checking}
Extracting type invariants is helpful in a variety of ways---type safety is an important property and types are lightweight annotations that can be quickly and efficiently checked.
Dynamic analysis can be used to generate type assertions or invariants
For example

To make this concrete, we are using
The static type system is defined as a variant of a simply-typed lambda calculus augmented with union types.

\heading{Learning, Synthesis, and Regeneration}
Extracting type invariants is helpful in a variety of ways---type safety is an important property and types are lightweight annotations that can be quickly and efficiently checked.
Dynamic analysis can be used to generate type assertions or invariants
For example
The approach has been pioneered by systems such as 

To make this concrete, we are using
The static type system is defined as a variant of a simply-typed lambda calculus augmented with union types.


\subsection{Design Goals}

We have briefly introduced four motivating analyses for extracting information about an application's dependencies.
While the challenges behind these analyses share several characteristics, today they remain largely unaddressed by dynamic analyses systems as these 

require highly specialized solutions often outside the core language,
do not leverage or offer semantic information at the level of module boundaries,
or lead to a high (often impractical) performance overheads due to the high granularity of their analyses.
These applications clearly illustrate the need for a system 
To summarize, these applications would appear to be served well by a system that:
\begin{itemize}
  \item Operates at the level of modules, both semantics and performance-wise
  \item Does not require learning a new tool or language---on the contrary,
    developers
  \item can be bolt onto an existing runtime as a library, regardless of whether 
  \item supports programmable analyses
\end{itemize}

In the next section we describe the design \sys, a new dynamic analyses
framework that satisfies these goals

\section{Module-aware Dynamic Analysis}
\label{design}

\subsection{Overview}

At a high level, dialysis works at three stages:

: Fracture the programs into shards â€” pieces
of the programs that implement a computation or functionality. The granularity of the fracture determines
the size of the shards. Potentially useful granularities
include functions, procedures, classes, abstract data
types, modules, loops, and program slices. Program
fracture typically includes the encapsulation of each
shard into its own separately invocable program for
testing, analysis, and exploration.


\section{Applications of Analysis}
\label{apps}


\section{Implementation: Lya}
\label{impl}

We implemented \sys for version 
We show where other implementations would diverge in table 1

The following subsections outline how module systems handle modules at runtime, by exemplifying the internals of Node.js.
It sketches the Node.js runtime~\sx{a}, the use of the module system~\sx{b}, and the internals of how module loading works~\sx{c}.

(1) why node.js
(2) Create a table of compatibility and show individual aspects

\heading{Module System}
Node.js' module system is implemented entirely in JavaScript.
It exposes \ttt{require}, a global-looking function for importing modules.
\fixme{Figure} above demonstrates the use of \ttt{require}.

% \begin{lstlisting}[language=js,mathescape,upquote=true]
% // -------------- [./main.js] -------------
% // importing point
% let Point = require("./point.js");
% Point.create(1, 1).print(); // => [1, 1]
% 
% // -------------- [./point.js] ------------
% let Point = function Point (x, y) {
%     this.x = x; this.y = y;
% };
% Point.prototype.print = function print () {
%   console.log([this.x, this.y]);
% };
% module.exports = {
%     create:  function create (x, y) {
%         return new Point(x, y);
%     }
% };
% \end{lstlisting}

In the example above, the main module (\ttt{main.js}) imports the \ttt{point.js} module using the \ttt{require} statement (line 3)
Functionality from the exporting module (\ttt{point.js}) that is expected to become available to the importing module (\ttt{main.js}) is assigned to a special \ttt{module.exports} object (line 13);
  the rest is module-private functionality.
Files and modules are in one-to-one correspondence (each file is treated as a separate module).
Method \ttt{require} is synchronous (\ie blocking):
  it will block execution until the module specified is loaded.
% ---and can be used to load built-in modules such as \ttt{http} and \ttt{fs}.
The module system is implemented in the \ttt{module} built-in module~\sx{c}, which locates, wraps, compiles, and executes the specified file.

\sys hooks into \ttt{module} and alters the return value of the \ttt{require} call that imports \ttt{point.js} (line 3).

\subsection{Implementation of the Module System}
\label{c}

At a very high level, loading a fresh module with \ttt{require("foo");} corresponds to the following five stages:

\begin{enumerate}
% \def\labelenumi{\arabic{enumi}.}
\item Resolution: identify the file to which the module specified corresponds, and locate it in the filesystem.
\item Loading: depending on the file type, use the corresponding loader (\eg V8 compiler for \ttt{js}, \ttt{JSON.parse} for \ttt{json} \etc).
\item Wrapping: wrap the module so that module-globals get encapsulated and Node.js globals (\eg \ttt{require}) get resolved.
\item Evaluation: evaluate the wrapped module in the current context, so that global names and top-level objects get resolved correctly.
\item Caching: add the module to a handful of module-related cache structures, for purposes of consistency and performance.
\end{enumerate}

% The resolution algorithm is somewhat convoluted, because it depends on several different facts (including the type of the file requested, whether it is a globally installed, whether it is a directory \etc).
% It does not require any \sys support beyond copying the directory that contains the source code of the all the modules onto the remote host.
\sys interposes on all of these steps to facilitate transformations.
Wrapping (3) and evaluation (4) are particularly interesting, because they allow \sys to interpose at the module boundary during runtime.
Before a module's code is evaluated, the Node.js module loader wraps the module so that
  (i) it keeps top-level variables (defined with \ttt{var}, \ttt{const} or \ttt{let}) scoped to the module rather than the global object; and
  (ii) it provides some global-looking variables that are actually specific to the module, such as the \ttt{module} and \ttt{exports} objects that the implementor can use to export values from the module and convenience variables---such as \ttt{\_\_filename} and \ttt{\_\_dirname}  containing the module's absolute filename and directory path, respectively.
True globals remaining are
  (i) the global objects as defined by the EcmaScript standard (\eg \ttt{Object}, \ttt{Function}, \ttt{Math}); and
  (ii) Node.js-specific globals (\eg \ttt{console}, \ttt{process}, \ttt{timer}).
These globals require further interposition.

% \begin{lstlisting}[language=js,mathescape,upquote=true]
% // Node.js will wrap a module with a function,
% // so as to bring certain names into scope
% // before compiling/evaluating code.
% let wrapped = "function (" +
%         "exports, require, module, " +
%         "__filename, __dirname, CTX) {" +
%     "let Math = CTX.Math" +
%     "let console = CTX.console" +
%     //...[more definitions]
%     moduleSource +
%   "});"
% \end{lstlisting}


\sys hooks into the wrapper function (the last variable in the function definition, \ttt{CTX}).
This trivial source-to-source transformation re-defines global variables as module-locals and initializes them with \sys-augmented values.
For example, \ttt{console} in the context of the module will be an \sys-created object that allows \sys to interpose on it.
Evaluation of the module passes an additional value to this function, which is the modified context.
As a result, any changes to the top-level objects and any global variables are accessible from the within the module.

% \begin{lstlisting}[language=js,mathescape,upquote=true]
% //Input: module ID e.g., absolute filepath
% let load = function (ID) {
%   if (cache[ID]) {
%      return cache[ID];
%   }
%   let m = {
%     exports: {}, id: ID, dir: path.resolve(ID)
%   };
%   let cm = v8.compile(wrapped);
%   let ii = iris.getImplicit(ID);
%   let c = iris.freshContext(ii);
%   cm(m.exports, this.require, m, ID, m.dir, c);
%   let ei = iris.getExplicit(ID);
%   m.exports = iris.wrap(m.exports, [ei] );
%   cache[ID] = m;
%   return m.exports;
% }
% \end{lstlisting}

The \ttt{load} method in the \ttt{Module} module combines evaluation (line 10) and caching (line 14) of the wrapped module.
After evaluation, invoking the compiled function generates the value that is assigned to \ttt{module.exports} from within the module (line 12).
\sys passes a freshly constructed context at that invocation, modified according to the implicit segment of the (PIC??) corresponding to the module being loaded.
Before returning the value of \ttt{module.exports}, \sys transforms it according to the explicit segment of the (PIC??) corresponding to the module being loaded.
Finally, the results of the entire process are placed into the module cache for later use.

\

\section{Evaluation}
\label{eval}

\subsection{Micro-benchmarks}
\label{micro}

\subsection{Single-module Benchmarks}
\label{meso}

\subsection{End-to-End Benchmarks}
\label{macro}

\section{Discussion and Limitations}
\label{diss}

\section{Related Work}
\label{rw}
Some citations to ensure we can see them~\cite{Christophe:2015:DAU:2819009.2819180, Keil:2013:EDA:2508168.2508176, Lehmann:2019:WFD:3297858.3304068, Sun:2018:EDA:3178372.3179527}.

\section{Conclusion}
\label{end}

% \section*{Acknowledgments}
% 
% \section*{Availability}

\bibliographystyle{plain}
\bibliography{bib}

\end{document}

%%  LocalWords:  endnotes includegraphics fread ptr nobj noindent
%%  LocalWords:  pdflatex acks
